{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW_Tensor_Flow.ipynb","provenance":[{"file_id":"https://github.com/yandexdataschool/Practical_RL/blob/spring20/week04_%5Brecap%5D_deep_learning/seminar_tensorflow.ipynb","timestamp":1595946072441}],"collapsed_sections":["Q5pTevDFxx4O"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5z9nT334xx37","colab_type":"text"},"source":["# Practice 3: my first tensorflow network\n","Your ultimate task for this week is to build your first neural network [almost] from scratch and pure tensorflow.\n","\n","This time you will same digit recognition problem, but at a larger scale\n","* images are now 28x28\n","* 10 different digits\n","* 50k samples\n","\n","Note that you are not required to build 152-layer monsters here. A 2-layer (one hidden, one output) NN should already have ive you an edge over logistic regression.\n","\n","__[bonus score]__\n","If you've already beaten logistic regression with a two-layer net, but enthusiasm still ain't gone, you can try improving the test accuracy even further! The milestones would be 95%/97.5%/98.5% accura—Åy on test set.\n","\n","__SPOILER!__\n","At the end of the notebook you will find a few tips and frequently made mistakes. If you feel enough might to shoot yourself in the foot without external assistance, we encourage you to do so, but if you encounter any unsurpassable issues, please do look there before mailing us."]},{"cell_type":"code","metadata":{"id":"DmSc0EQf0lza","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1595946643170,"user_tz":-120,"elapsed":681,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"889289bc-450a-4756-c12d-dcf6407b2b91"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IXm1fkuIxx38","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1595947991702,"user_tz":-120,"elapsed":1100,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"2d7144de-9d43-491b-8660-273dba9bee99"},"source":["mnist = tf.keras.datasets.mnist\n","\n","# [down]loading the original MNIST dataset.\n","# Please note that you should only train your NN on _train sample,\n","#  _val can be used to evaluate out-of-sample error, compare models or perform early-stopping\n","#  _test should be hidden under a rock untill final evaluation... But we both know it is near impossible to catch you evaluating on it.\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train / 255.0\n","X_test  = X_test  / 255.0\n","\n","print(X_train.shape, y_train.shape)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["(60000, 28, 28) (60000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vYxVbVH7xx4A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1595947993925,"user_tz":-120,"elapsed":834,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"15d718a0-54dd-4751-f38f-4f9bfa583fdc"},"source":["plt.imshow(X_train[0, :,:])"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f8169b141d0>"]},"metadata":{"tags":[]},"execution_count":35},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"enUqlcILxx4C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595946789321,"user_tz":-120,"elapsed":737,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVI82jc4xx4E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"status":"ok","timestamp":1595947770543,"user_tz":-120,"elapsed":51651,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"e261c11b-753c-4724-888e-43ab579e5838"},"source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.996):\n","      print(\"\\nReached 99% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","model = tf.keras.models.Sequential(\n","    [tf.keras.layers.Flatten(),\n","     tf.keras.layers.Dense(128, activation = tf.nn.relu),\n","     tf.keras.layers.Dense(64, activation = tf.nn.relu),\n","     tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n","])\n","\n","model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","Epoch = 30\n","model.fit(X_train, \n","          y_train, \n","          epochs=Epoch, \n","          callbacks=[myCallback()])\n","model.evaluate(X_test, y_test)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.9310\n","Epoch 2/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0995 - accuracy: 0.9704\n","Epoch 3/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0720 - accuracy: 0.9775\n","Epoch 4/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0550 - accuracy: 0.9827\n","Epoch 5/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0424 - accuracy: 0.9863\n","Epoch 6/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0354 - accuracy: 0.9884\n","Epoch 7/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0285 - accuracy: 0.9905\n","Epoch 8/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0230 - accuracy: 0.9924\n","Epoch 9/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0221 - accuracy: 0.9920\n","Epoch 10/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0196 - accuracy: 0.9936\n","Epoch 11/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0158 - accuracy: 0.9948\n","Epoch 12/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0149 - accuracy: 0.9952\n","Epoch 13/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0150 - accuracy: 0.9948\n","Epoch 14/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 0.9959\n","Epoch 15/30\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9960\n","Epoch 16/30\n","1863/1875 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9963\n","Reached 99% accuracy so cancelling training!\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0105 - accuracy: 0.9964\n","313/313 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9792\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.11330655217170715, 0.979200005531311]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"aVZSYOzB9CCl","colab_type":"text"},"source":["Using Conv Nets, yields Better approximation\n"]},{"cell_type":"code","metadata":{"id":"sYcLIHUF56ft","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1595948482626,"user_tz":-120,"elapsed":1374,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"eb0dd215-9796-44d0-e7cf-edce1d5bb19e"},"source":["# Conv Net = Better approximation\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.996):\n","      print(\"\\n Reached 99.6% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","mnist = tf.keras.datasets.mnist\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train / 255.0\n","X_train = X_train.reshape(60000, 28, 28, 1)\n","\n","X_test  = X_test  / 255.0\n","X_test  = X_test.reshape(10000, 28, 28, 1)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WGm8Ato68JZz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1595948521474,"user_tz":-120,"elapsed":34070,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"f1829226-053b-4d1c-ea97-4e6c5819827d"},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, \n","          epochs=10, callbacks=[myCallback()])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.1442 - accuracy: 0.9571\n","Epoch 2/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0472 - accuracy: 0.9858\n","Epoch 3/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0320 - accuracy: 0.9896\n","Epoch 4/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0238 - accuracy: 0.9926\n","Epoch 5/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0172 - accuracy: 0.9944\n","Epoch 6/10\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0148 - accuracy: 0.9951\n","Epoch 7/10\n","1867/1875 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9965\n"," Reached 99.6% accuracy so cancelling training!\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0105 - accuracy: 0.9964\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f927003fb70>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"q3JCYLbz8R08","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1595948525357,"user_tz":-120,"elapsed":1912,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"93bf94e5-27e7-4d24-8739-3d18d040f2ae"},"source":["test_loss, test_acc = model.evaluate(X_test, y_test)\n","print('Test loss: ', test_loss)\n","print('Test accuracy: ', test_acc)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9895\n","Test loss:  0.0362049899995327\n","Test accuracy:  0.9894999861717224\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vSmrdROKz4om","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"IH7_Q3qixx4K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1595948577525,"user_tz":-120,"elapsed":1909,"user":{"displayName":"Pavel Kolev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEXJS7sNFign0FwJAol1njlYVw7u2db6pzfVQUtA=s64","userId":"10114955063697182799"}},"outputId":"2a9cc9eb-e529-4c98-aaf0-c955de4d3a5e"},"source":["f = model.predict(X_test)\n","\n","k = 0\n","print(f[k], np.argmax(f[k]), y_test[k])\n","plt.imshow(X_train[k, :, :, 0])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[5.4369192e-10 2.0259451e-07 2.2153328e-10 2.0871562e-07 2.4836308e-10\n"," 2.0835542e-11 5.9884245e-16 9.9999952e-01 1.5908522e-10 8.4382705e-08] 7 7\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f921c87e780>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Q5pTevDFxx4O","colab_type":"text"},"source":["```\n","\n","```\n","\n","```\n","\n","```\n","\n","```\n","\n","```\n","\n","\n","# SPOILERS!\n","\n","Recommended pipeline\n","\n","* Adapt logistic regression from previous assignment to classify some number against others (e.g. zero vs nonzero)\n","* Generalize it to multiclass logistic regression.\n","  - Either try to remember lecture 0 or google it.\n","  - Instead of weight vector you'll have to use matrix (feature_id x class_id)\n","  - softmax (exp over sum of exps) can implemented manually or as T.nnet.softmax (stable)\n","  - probably better to use STOCHASTIC gradient descent (minibatch)\n","    - in which case sample should probably be shuffled (or use random subsamples on each iteration)\n","* Add a hidden layer. Now your logistic regression uses hidden neurons instead of inputs.\n","  - Hidden layer uses the same math as output layer (ex-logistic regression), but uses some nonlinearity (sigmoid) instead of softmax\n","  - You need to train both layers, not just output layer :)\n","  - Do not initialize layers with zeros (due to symmetry effects). A gaussian noize with small sigma will do.\n","  - 50 hidden neurons and a sigmoid nonlinearity will do for a start. Many ways to improve. \n","  - In ideal casae this totals to 2 .dot's, 1 softmax and 1 sigmoid\n","  - __make sure this neural network works better than logistic regression__\n","  \n","* Now's the time to try improving the network. Consider layers (size, neuron count),  nonlinearities, optimization methods, initialization - whatever you want, but please avoid convolutions for now."]}]}