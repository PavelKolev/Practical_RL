{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w8_practice_lstm_distinct_tf_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxrhkGBVY4UN",
        "colab_type": "text"
      },
      "source": [
        "### Deep Kung-Fu with advantage actor-critic\n",
        "\n",
        "In this notebook you'll build a deep reinforcement learning agent for Atari [Kung-Fu Master](https://gym.openai.com/envs/KungFuMaster-v0/) that uses a recurrent neural net.\n",
        "\n",
        "![https://upload.wikimedia.org/wikipedia/en/6/66/Kung_fu_master_mame.png](https://upload.wikimedia.org/wikipedia/en/6/66/Kung_fu_master_mame.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRUw7nQHY4UO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4daabd9-fdac-43c4-fe63-4ad59a2837fc"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://github.com/yandexdataschool/Practical_RL/issues/256\n",
        "    !pip uninstall tensorflow --yes\n",
        "    !pip uninstall keras --yes\n",
        "    !pip install tensorflow-gpu==1.13.1\n",
        "    !pip install keras==2.2.4\n",
        "    \n",
        "    if not os.path.exists('.setup_complete'):\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week08_pomdp/atari_util.py\n",
        "        \n",
        "        !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.31.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (49.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhkyrISI5lA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "A thin wrapper for openAI gym environments that maintains a set of parallel games and has a method to generate\n",
        "interaction sessions given agent one-step applier function.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# A whole lot of space invaders\n",
        "\n",
        "\n",
        "class EnvPool(object):\n",
        "    def __init__(self, actor, critic, make_env, n_parallel_games=1):\n",
        "        \"\"\"\n",
        "        A special class that handles training on multiple parallel sessions\n",
        "        and is capable of some auxilary actions like evaluating agent on one game session (See .evaluate()).\n",
        "\n",
        "        :param agent: Agent which interacts with the environment.\n",
        "        :param make_env: Factory that produces environments OR a name of the gym environment.\n",
        "        :param n_games: Number of parallel games. One game by default.\n",
        "        :param max_size: Max pool size by default (if appending sessions). By default, pool is not constrained in size.\n",
        "        \"\"\"\n",
        "        # Create atari games.\n",
        "        self.actor  = actor\n",
        "        self.critic = critic\n",
        "        self.make_env = make_env\n",
        "        self.envs = [self.make_env() for _ in range(n_parallel_games)]\n",
        "\n",
        "        # Initial observations.\n",
        "        self.prev_observations = [env.reset() for env in self.envs]\n",
        "\n",
        "        # Agent memory variables (if you use recurrent networks).\n",
        "        self.prev_memory_states_actor  = actor.get_initial_state(n_parallel_games)\n",
        "        self.prev_memory_states_critic = critic.get_initial_state(n_parallel_games)\n",
        "\n",
        "        # Whether particular session has just been terminated and needs\n",
        "        # restarting.\n",
        "        self.just_ended = [False] * len(self.envs)\n",
        "\n",
        "\n",
        "    def interact(self, n_steps=100, verbose=False):\n",
        "        \"\"\"Generate interaction sessions with ataries (openAI gym atari environments)\n",
        "        Sessions will have length n_steps. Each time one of games is finished, it is immediately getting reset\n",
        "        and this time is recorded in is_alive_log (See returned values).\n",
        "\n",
        "        :param n_steps: Length of an interaction.\n",
        "        :returns: observation_seq, action_seq, reward_seq, is_alive_seq\n",
        "        :rtype: a bunch of tensors [batch, tick, ...]\n",
        "        \"\"\"\n",
        "\n",
        "        def env_step(i, action):\n",
        "            if not self.just_ended[i]:\n",
        "                new_observation, cur_reward, is_done, info = self.envs[i].step(action)\n",
        "                if is_done:\n",
        "                    # Game ends now, will finalize on next tick.\n",
        "                    self.just_ended[i] = True\n",
        "\n",
        "                # note: is_alive=True in any case because environment is still\n",
        "                # alive (last tick alive) in our notation.\n",
        "                return new_observation, cur_reward, True, info\n",
        "            else:\n",
        "                # Reset environment, get new observation to be used on next\n",
        "                # tick.\n",
        "                new_observation = self.envs[i].reset()\n",
        "\n",
        "                # Reset memory for new episode.\n",
        "                initial_memory_state_actor  = self.actor.get_initial_state(batch_size=1)\n",
        "                initial_memory_state_critic = self.critic.get_initial_state(batch_size=1)\n",
        "\n",
        "                for m_i in range(len(new_memory_states_actor)):\n",
        "                    new_memory_states_actor[m_i][i]  = initial_memory_state_actor[m_i][0]\n",
        "\n",
        "                for m_i in range(len(new_memory_states_critic)):\n",
        "                    new_memory_states_critic[m_i][i] = initial_memory_state_critic[m_i][0]\n",
        "\n",
        "                if verbose:\n",
        "                    print(\"env %i reloaded\" % i)\n",
        "\n",
        "                self.just_ended[i] = False\n",
        "\n",
        "                return new_observation, 0, False, {'end': True}\n",
        "\n",
        "        history_log = []\n",
        "        \n",
        "        last_prev_mem_state_actor  = self.prev_memory_states_actor\n",
        "        last_prev_mem_state_critic = self.prev_memory_states_critic\n",
        "\n",
        "        for i in range(n_steps):\n",
        "            new_memory_states_actor, logits = self.actor.step(self.prev_memory_states_actor, \n",
        "                                                              self.prev_observations)\n",
        "            sampled_actions = self.actor.sample_actions(logits)\n",
        "\n",
        "            new_memory_states_critic, state_values = self.critic.step(self.prev_memory_states_critic,\n",
        "                                                                      self.prev_observations)\n",
        "\n",
        "            new_observations, cur_rewards, is_alive, infos = zip(\n",
        "                *map(env_step, range(len(self.envs)), sampled_actions))\n",
        "            \n",
        "            \n",
        "            # Append data tuple for this tick.\n",
        "            history_log.append(\n",
        "                (self.prev_observations, sampled_actions, cur_rewards, is_alive))\n",
        "\n",
        "            \n",
        "            self.prev_observations  = new_observations\n",
        "\n",
        "            last_prev_mem_state_actor  = self.prev_memory_states_actor\n",
        "            last_prev_mem_state_critic = self.prev_memory_states_critic\n",
        "\n",
        "            self.prev_memory_states_actor  = new_memory_states_actor\n",
        "            self.prev_memory_states_critic = new_memory_states_critic\n",
        "            \n",
        "            \n",
        "\n",
        "        # add last observation\n",
        "        #dummy_actions = [0] * len(self.envs)\n",
        "        #dummy_rewards = [0] * len(self.envs)\n",
        "        #dummy_mask = [1] * len(self.envs)\n",
        "        #history_log.append(\n",
        "        #    (self.prev_observations,\n",
        "        #     dummy_actions,\n",
        "        #     dummy_rewards,\n",
        "        #     dummy_mask))\n",
        "\n",
        "        # cast to numpy arrays, \n",
        "        # transpose from [time, batch, ...] to [batch, time, ...]\n",
        "        history_log = [\n",
        "            np.array(tensor).swapaxes(0, 1)\n",
        "            for tensor in zip(*history_log)\n",
        "        ]\n",
        "        observation_seq, action_seq, reward_seq, is_alive_seq = history_log\n",
        "\n",
        "        return observation_seq, action_seq, reward_seq, is_alive_seq, last_prev_mem_state_critic\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm35vEADY4UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import display"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pI8-QsiY4UW",
        "colab_type": "text"
      },
      "source": [
        "For starters, let's take a look at the game itself:\n",
        "\n",
        "* Image resized to 42x42 and converted to grayscale to run faster\n",
        "* Agent sees last 4 frames of game to account for object velocity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg8qz_iMY4UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c241c883-71d2-4d48-c4c0-af8d7caf0889"
      },
      "source": [
        "import gym\n",
        "from atari_util import PreprocessAtari\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"KungFuMasterDeterministic-v0\")\n",
        "    env = PreprocessAtari(\n",
        "        env, height=42, width=42,\n",
        "        crop=lambda img: img[60:-30, 5:],\n",
        "        dim_order='tensorflow',\n",
        "        color=False, n_frames=4)\n",
        "    return env\n",
        "\n",
        "env = make_env()\n",
        "\n",
        "obs_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"Observation shape:\", obs_shape)\n",
        "print(\"Num actions:\", n_actions)\n",
        "print(\"Action names:\", env.env.env.get_action_meanings())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation shape: (42, 42, 4)\n",
            "Num actions: 14\n",
            "Action names: ['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z658owR2Y4Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "e037f7a4-23d1-47a3-9373-005a80da7c74"
      },
      "source": [
        "s = env.reset()\n",
        "for _ in range(100):\n",
        "    s, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "plt.title('Game image')\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()\n",
        "\n",
        "plt.title('Agent observation (4-frame buffer)')\n",
        "plt.imshow(s.transpose([0, 2, 1]).reshape([42,-1]))\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-iqdJDMY4Uf",
        "colab_type": "text"
      },
      "source": [
        "### Simple agent for fully-observable MDP\n",
        "\n",
        "Here's a code for an agent that only uses feedforward layers. Please read it carefully: you'll have to extend it later!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiTI0SnkY4Ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d3b2437c-2948-49d0-84ac-9af189cb7951"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.nn.rnn_cell import LSTMCell, LSTMStateTuple\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff74wi7RY4Uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleRecurrentAgent_Q:\n",
        "    def __init__(self, name, obs_shape, n_actions, reuse=False):\n",
        "        \"\"\"A simple actor-critic agent\"\"\"\n",
        "\n",
        "        with tf.variable_scope(name, reuse=reuse):\n",
        "            # Note: number of units/filters is arbitrary, you can and should change it at your will\n",
        "             # Note: number of units/filters is arbitrary, you can and should change it at your will\n",
        "            self.conv0 = Conv2D(32, (4, 4), strides=(2, 2), activation='relu')\n",
        "            self.conv1 = Conv2D(64, (3, 3), strides=(2, 2), activation='relu')\n",
        "            self.conv2 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')\n",
        "\n",
        "            self.flatten = Flatten()\n",
        "            self.hid     = Dense(128, activation='relu')\n",
        "            \n",
        "            # Actor: pi(a|s)\n",
        "            self.logits  = Dense(n_actions)\n",
        "            \n",
        "            # Recurrent Layer\n",
        "            self.hid_size  = 128\n",
        "            self.rnn0 = LSTMCell(self.hid_size, state_is_tuple = True)\n",
        "\n",
        "            # prepare a graph for agent step\n",
        "            initial_state_c = tf.placeholder(dtype=tf.float32, \n",
        "                                             shape=[None, self.hid_size],\n",
        "                                             name=\"init_state_c\")\n",
        "            \n",
        "            initial_state_h = tf.placeholder(dtype=tf.float32, \n",
        "                                             shape=[None, self.hid_size],\n",
        "                                             name=\"init_state_h\")\n",
        "            \n",
        "            self.prev_state_placeholder = LSTMStateTuple(initial_state_c, initial_state_h)\n",
        "\n",
        "            self.obs_t = tf.placeholder(tf.float32, [None, ] + list(obs_shape))\n",
        "\n",
        "            self.next_state, self.agent_outputs = self.symbolic_step(self.prev_state_placeholder,\n",
        "                                                                     self.obs_t)\n",
        "            \n",
        "            self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n",
        "                                               scope = name)\n",
        "            \n",
        "            print(\"\\n\" + \"Model Summary (\" + name + \")\")\n",
        "            for t in self.variables:\n",
        "                print(t)\n",
        "            \n",
        "\n",
        "\n",
        "    def symbolic_step(self, prev_state, obs_t):\n",
        "        \"\"\"Takes agent's previous step and observation, returns next state and whatever it needs to learn (tf tensors)\"\"\"\n",
        "        nn = self.conv0(obs_t)\n",
        "        nn = self.conv1(nn)\n",
        "        nn = self.conv2(nn)\n",
        "        nn = self.flatten(nn)\n",
        "        nn = self.hid(nn)\n",
        "        \n",
        "        # Apply recurrent neural net for one step here.\n",
        "        # The recurrent cell should take the last feedforward dense layer as input.\n",
        "        batch_ones = tf.ones(tf.shape(obs_t)[0])\n",
        "        new_out, new_state_ch = tf.nn.dynamic_rnn(self.rnn0, nn[:,None],\n",
        "                                                  initial_state = prev_state,\n",
        "                                                  sequence_length = batch_ones)\n",
        "        \n",
        "        logits = self.logits(new_out[:,0])\n",
        "\n",
        "        return new_state_ch, logits\n",
        "\n",
        "\n",
        "    def get_initial_state(self, batch_size):\n",
        "        # LSTMStateTuple([batch_size x hid_size], [batch_size x hid_size]]\n",
        "        a = np.zeros([batch_size, self.hid_size], dtype=np.float32)\n",
        "        return LSTMStateTuple(a, a)\n",
        "\n",
        "\n",
        "    # Instantiation\n",
        "    def step(self, prev_state, obs_t):\n",
        "        \"\"\"Same as symbolic state except it operates on numpy arrays\"\"\"\n",
        "        sess = tf.get_default_session()\n",
        "        \n",
        "        feed_dict = {self.obs_t: obs_t,\n",
        "                     self.prev_state_placeholder: prev_state}\n",
        "        \n",
        "        return sess.run([self.next_state, self.agent_outputs], feed_dict)\n",
        "\n",
        "\n",
        "    def sample_actions(self, logits):\n",
        "        \"\"\"pick actions given numeric agent outputs (np arrays)\"\"\"\n",
        "        policy = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
        "\n",
        "        return [np.random.choice(len(p), p=p) for p in policy]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5BXsxvgmDKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleRecurrentAgent_V:\n",
        "    def __init__(self, name, obs_shape, n_actions, reuse=False):\n",
        "        \"\"\"A simple actor-critic agent\"\"\"\n",
        "\n",
        "        with tf.variable_scope(name, reuse=reuse):\n",
        "            # Note: number of units/filters is arbitrary, you can and should change it at your will\n",
        "             # Note: number of units/filters is arbitrary, you can and should change it at your will\n",
        "            self.conv0 = Conv2D(32, (4, 4), strides=(2, 2), activation='relu')\n",
        "            self.conv1 = Conv2D(64, (3, 3), strides=(2, 2), activation='relu')\n",
        "            self.conv2 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')\n",
        "\n",
        "            self.flatten = Flatten()\n",
        "            self.hid     = Dense(128, activation='relu')\n",
        "            \n",
        "            # Critic: State Values\n",
        "            self.state_value = Dense(1)\n",
        "            \n",
        "            # Recurrent Layer\n",
        "            self.hid_size  = 128\n",
        "            self.rnn0 = LSTMCell(self.hid_size, state_is_tuple = True)\n",
        "\n",
        "            # prepare a graph for agent step\n",
        "            initial_state_c = tf.placeholder(dtype=tf.float32, \n",
        "                                             shape=[None, self.hid_size],\n",
        "                                             name=\"init_state_c\")\n",
        "            \n",
        "            initial_state_h = tf.placeholder(dtype=tf.float32, \n",
        "                                             shape=[None, self.hid_size],\n",
        "                                             name=\"init_state_h\")\n",
        "            \n",
        "            self.prev_state_placeholder = LSTMStateTuple(initial_state_c, initial_state_h)\n",
        "\n",
        "            self.obs_t = tf.placeholder(tf.float32, [None, ] + list(obs_shape))\n",
        "\n",
        "            self.next_state, self.agent_outputs = self.symbolic_step(self.prev_state_placeholder,\n",
        "                                                                     self.obs_t)\n",
        "            \n",
        "            self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n",
        "                                               scope = name)\n",
        "            \n",
        "            print(\"\\n\" + \"Model Summary (\" + name + \")\")\n",
        "            for t in self.variables:\n",
        "                print(t)\n",
        "            \n",
        "\n",
        "\n",
        "    def symbolic_step(self, prev_state, obs_t):\n",
        "        \"\"\"Takes agent's previous step and observation, returns next state and whatever it needs to learn (tf tensors)\"\"\"\n",
        "        nn = self.conv0(obs_t)\n",
        "        nn = self.conv1(nn)\n",
        "        nn = self.conv2(nn)\n",
        "        nn = self.flatten(nn)\n",
        "        nn = self.hid(nn)\n",
        "        \n",
        "        # Apply recurrent neural net for one step here.\n",
        "        # The recurrent cell should take the last feedforward dense layer as input.\n",
        "        batch_ones = tf.ones(tf.shape(obs_t)[0])\n",
        "        new_out, new_state_ch = tf.nn.dynamic_rnn(self.rnn0, nn[:,None],\n",
        "                                                  initial_state = prev_state,\n",
        "                                                  sequence_length = batch_ones)\n",
        "        \n",
        "        state_value = self.state_value(new_out[:,0])\n",
        "\n",
        "        return new_state_ch, state_value\n",
        "\n",
        "\n",
        "    def get_initial_state(self, batch_size):\n",
        "        # LSTMStateTuple([batch_size x hid_size], [batch_size x hid_size]]\n",
        "        a = np.zeros([batch_size, self.hid_size], dtype=np.float32)\n",
        "        return LSTMStateTuple(a, a)\n",
        "\n",
        "\n",
        "    # Instantiation\n",
        "    def step(self, prev_state, obs_t):\n",
        "        \"\"\"Same as symbolic state except it operates on numpy arrays\"\"\"\n",
        "        sess = tf.get_default_session()\n",
        "        \n",
        "        feed_dict = {self.obs_t: obs_t,\n",
        "                     self.prev_state_placeholder: prev_state}\n",
        "        \n",
        "        return sess.run([self.next_state, self.agent_outputs], feed_dict)\n",
        "\n",
        "\n",
        "    def get_state_values(self, prev_state, obs_t):\n",
        "        sess = tf.get_default_session()\n",
        "        \n",
        "        feed_dict = {self.obs_t: obs_t,\n",
        "                     self.prev_state_placeholder: prev_state}\n",
        "        \n",
        "        return sess.run(self.agent_outputs, feed_dict)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKfAXDe1Y4Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "0cf0afb6-5cad-4b11-9c6a-2766d6d75133"
      },
      "source": [
        "n_parallel_games = 10\n",
        "rollout_length   = 25\n",
        "gamma = 0.99\n",
        "\n",
        "actor  = SimpleRecurrentAgent_Q('actor',  obs_shape, n_actions)\n",
        "critic = SimpleRecurrentAgent_V('critic', obs_shape, n_actions)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-2480f0676f4d>:20: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-7-2480f0676f4d>:60: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "Model Summary (actor)\n",
            "<tf.Variable 'actor/conv2d_1/kernel:0' shape=(4, 4, 4, 32) dtype=float32_ref>\n",
            "<tf.Variable 'actor/conv2d_1/bias:0' shape=(32,) dtype=float32_ref>\n",
            "<tf.Variable 'actor/conv2d_2/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
            "<tf.Variable 'actor/conv2d_2/bias:0' shape=(64,) dtype=float32_ref>\n",
            "<tf.Variable 'actor/conv2d_3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
            "<tf.Variable 'actor/conv2d_3/bias:0' shape=(64,) dtype=float32_ref>\n",
            "<tf.Variable 'actor/dense_1/kernel:0' shape=(3136, 128) dtype=float32_ref>\n",
            "<tf.Variable 'actor/dense_1/bias:0' shape=(128,) dtype=float32_ref>\n",
            "<tf.Variable 'actor/rnn/lstm_cell/kernel:0' shape=(256, 512) dtype=float32_ref>\n",
            "<tf.Variable 'actor/rnn/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>\n",
            "<tf.Variable 'actor/dense_2/kernel:0' shape=(128, 14) dtype=float32_ref>\n",
            "<tf.Variable 'actor/dense_2/bias:0' shape=(14,) dtype=float32_ref>\n",
            "\n",
            "Model Summary (critic)\n",
            "<tf.Variable 'critic/conv2d_4/kernel:0' shape=(4, 4, 4, 32) dtype=float32_ref>\n",
            "<tf.Variable 'critic/conv2d_4/bias:0' shape=(32,) dtype=float32_ref>\n",
            "<tf.Variable 'critic/conv2d_5/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
            "<tf.Variable 'critic/conv2d_5/bias:0' shape=(64,) dtype=float32_ref>\n",
            "<tf.Variable 'critic/conv2d_6/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
            "<tf.Variable 'critic/conv2d_6/bias:0' shape=(64,) dtype=float32_ref>\n",
            "<tf.Variable 'critic/dense_3/kernel:0' shape=(3136, 128) dtype=float32_ref>\n",
            "<tf.Variable 'critic/dense_3/bias:0' shape=(128,) dtype=float32_ref>\n",
            "<tf.Variable 'critic/rnn/lstm_cell/kernel:0' shape=(256, 512) dtype=float32_ref>\n",
            "<tf.Variable 'critic/rnn/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>\n",
            "<tf.Variable 'critic/dense_4/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
            "<tf.Variable 'critic/dense_4/bias:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjgYtYdwY4Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "39688903-8eeb-4df3-e6d4-1f1d1871410f"
      },
      "source": [
        "state = [env.reset()]\n",
        "_, logits       = actor.step(actor.get_initial_state(1), state)\n",
        "_, state_values = critic.step(critic.get_initial_state(1), state)\n",
        "print(\"action logits:\\n\", logits)\n",
        "print(\"state values:\\n\", state_values)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action logits:\n",
            " [[-0.01165732 -0.01234715  0.00920098  0.00207483 -0.00184921 -0.00266627\n",
            "   0.00050533  0.00414065  0.00437399  0.00013939 -0.00143254 -0.0081718\n",
            "   0.00056811  0.00049527]]\n",
            "state values:\n",
            " [[-0.00864113]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klqvnKWdY4Us",
        "colab_type": "text"
      },
      "source": [
        "### Let's play!\n",
        "Let's build a function that measures agent's average reward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln4WuILsY4Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(actor, env, n_games=1):\n",
        "    \"\"\"Plays an a game from start till done, returns per-game rewards \"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        # initial observation and memory\n",
        "        observation = env.reset()\n",
        "        prev_memories = actor.get_initial_state(1)\n",
        "\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            new_memories, readouts = actor.step(prev_memories, \n",
        "                                                observation[None, ...])\n",
        "            action = actor.sample_actions(readouts)\n",
        "\n",
        "            observation, reward, done, info = env.step(action[0])\n",
        "\n",
        "            total_reward += reward\n",
        "            prev_memories = new_memories\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PArnjUsxI4Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import gym.wrappers\n",
        "\n",
        "#with gym.wrappers.Monitor(make_env(), directory=\"videos\", force=True) as env_monitor:\n",
        "#    rewards = evaluate(actor, env_monitor, n_games=3)\n",
        "\n",
        "#print(rewards)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrmfSJAEY4Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "#from pathlib import Path\n",
        "#from IPython.display import HTML\n",
        "\n",
        "#video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "#HTML(\"\"\"\n",
        "#<video width=\"640\" height=\"480\" controls>\n",
        "#  <source src=\"{}\" type=\"video/mp4\">\n",
        "#</video>\n",
        "#\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff_83RwqY4U0",
        "colab_type": "text"
      },
      "source": [
        "### Training on parallel games\n",
        "\n",
        "We introduce a class called EnvPool - it's a tool that handles multiple environments for you. Here's how it works:\n",
        "![img](https://s7.postimg.cc/4y36s2b2z/env_pool.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q77ZJKGY4U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TARGET AGENT is used to sample\n",
        "pool = EnvPool(actor, critic, make_env, n_parallel_games)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF9OpsgRY4U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each of n_parallel_games, take \"rollout_length\" steps\n",
        "rollout_obs, rollout_actions, rollout_rewards, rollout_mask, last_prev_mem_state_critic = pool.interact(rollout_length)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HQ7gxu3Y4U8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "adf5c690-bac5-4a06-9193-f2e2422e8aa1"
      },
      "source": [
        "print(\"Actions shape:\", rollout_actions.shape)\n",
        "print(\"Rewards shape:\", rollout_rewards.shape)\n",
        "print(\"Mask shape:\", rollout_mask.shape)\n",
        "print(\"Observations shape: \", rollout_obs.shape)\n",
        "print(\"Last Previous Memory State: \", (last_prev_mem_state_critic[0].shape, last_prev_mem_state_critic[1].shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions shape: (10, 25)\n",
            "Rewards shape: (10, 25)\n",
            "Mask shape: (10, 25)\n",
            "Observations shape:  (10, 25, 42, 42, 4)\n",
            "Last Previous Memory State:  ((10, 128), (10, 128))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhyVE0AzY4VA",
        "colab_type": "text"
      },
      "source": [
        "# Actor-critic objective\n",
        "\n",
        "Here we define a loss function that uses rollout above to train advantage actor-critic agent.\n",
        "\n",
        "\n",
        "Our loss consists of three components:\n",
        "\n",
        "* __The policy \"loss\"__\n",
        " $$ \\hat J = {1 \\over T} \\cdot \\sum_t { \\log \\pi(a_t | s_t) } \\cdot A_{const}(s,a) $$\n",
        "  * This function has no meaning in and of itself, but it was built such that\n",
        "  * $ \\nabla \\hat J = {1 \\over N} \\cdot \\sum_t { \\nabla \\log \\pi(a_t | s_t) } \\cdot A(s,a) \\approx \\nabla E_{s, a \\sim \\pi} R(s,a) $\n",
        "  * Therefore if we __maximize__ J_hat with gradient descent we will maximize expected reward\n",
        "  \n",
        "  \n",
        "* __The value \"loss\"__\n",
        "  $$ L_{td} = {1 \\over T} \\cdot \\sum_t { [r + \\gamma \\cdot V_{const}(s_{t+1}) - V(s_t)] ^ 2 }$$\n",
        "  * Ye Olde TD_loss from q-learning and alike\n",
        "  * If we minimize this loss, V(s) will converge to $V_\\pi(s) = E_{a \\sim \\pi(a | s)} R(s,a) $\n",
        "\n",
        "\n",
        "* __Entropy Regularizer__\n",
        "  $$ H = - {1 \\over T} \\sum_t \\sum_a {\\pi(a|s_t) \\cdot \\log \\pi (a|s_t)}$$\n",
        "  * If we __maximize__ entropy we discourage agent from predicting zero probability to actions\n",
        "  prematurely (a.k.a. exploration)\n",
        "  \n",
        "  \n",
        "So we optimize a linear combination of $L_{td} - \\hat J -H$\n",
        "\n",
        "\n",
        "__One more thing:__ since we train on T-step rollouts, we can use N-step formula for advantage for free:\n",
        "  * At the last step, $A(s_t,a_t) = r(s_t, a_t) + \\gamma \\cdot V(s_{t+1}) - V(s) $\n",
        "  * One step earlier, $A(s_t,a_t) = r(s_t, a_t) + \\gamma \\cdot r(s_{t+1}, a_{t+1}) + \\gamma ^ 2 \\cdot V(s_{t+2}) - V(s) $\n",
        "  * Et cetera, et cetera. This way agent starts training much faster since it's estimate of A(s,a) depends less on his (imperfect) value function and more on actual rewards. There's also a [nice generalization](https://arxiv.org/abs/1506.02438) of this.\n",
        "\n",
        "\n",
        "__Note:__ it's also a good idea to scale rollout_len up to learn longer sequences. You may wish set it to >=20 or to start at 10 and then scale up as time passes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_98omkZY4VA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "5e83d0bc-6453-47e6-d98a-f98ffc303136"
      },
      "source": [
        "# Updatable agent\n",
        "\n",
        "# [batch, time, h, w, c]\n",
        "observations_ph       = tf.placeholder('float32', [None, None,] + list(obs_shape))\n",
        "sampled_actions_ph    = tf.placeholder('int32',   (None, None,))\n",
        "mask_ph               = tf.placeholder('float32', (None, None,))\n",
        "\n",
        "rewards_ph            = tf.placeholder('float32', (None, None,))\n",
        "cumulative_rewards_ph = tf.placeholder('float32', (None, None,))\n",
        "\n",
        "\n",
        "init_state_actor_ph  = actor.prev_state_placeholder\n",
        "init_state_critic_ph = critic.prev_state_placeholder\n",
        "\n",
        "# get new_state, (actor->logits, critic->state_value)\n",
        "next_state_actor, logits = actor.symbolic_step(init_state_actor_ph,\n",
        "                                               observations_ph[:, 0])\n",
        "\n",
        "next_state_critic, state_values = critic.symbolic_step(init_state_critic_ph,\n",
        "                                                       observations_ph[:, 0])\n",
        "\n",
        "def f(stack, obs_t):\n",
        "    init_state_actor, init_state_critic = stack[0], stack[1]\n",
        "    next_state_actor, logits = actor.symbolic_step(init_state_actor, obs_t)\n",
        "    next_state_critic, state_values = critic.symbolic_step(init_state_critic, obs_t)\n",
        "    return [next_state_actor, next_state_critic, logits, state_values]\n",
        "\n",
        "[next_state_seq_actor, next_state_seq_critic, logits_seq, state_values_seq] = tf.scan(\n",
        "    f,\n",
        "    initializer = [init_state_actor_ph, init_state_critic_ph, logits, state_values],\n",
        "    elems = tf.transpose(observations_ph, [1, 0, 2, 3, 4])\n",
        "    # elem.shape = [time, batch, h, w, c]\n",
        ")\n",
        "print(next_state_seq_actor)\n",
        "print(next_state_seq_critic)\n",
        "print(logits_seq)\n",
        "print(state_values_seq)\n",
        "\n",
        "\n",
        "# from [time, batch] back to [batch, time]\n",
        "logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
        "state_values_seq = tf.transpose(state_values_seq, [1, 0, 2])\n",
        "\n",
        "next_state_seq_actor  = [tf.transpose(tensor, [1, 0] + list(range(2, tensor.shape.ndims))) \n",
        "                         for tensor in next_state_seq_actor]\n",
        "next_state_seq_critic = [tf.transpose(tensor, [1, 0] + list(range(2, tensor.shape.ndims))) \n",
        "                         for tensor in next_state_seq_critic]\n",
        "\n",
        "print(logits_seq)\n",
        "print(state_values_seq)\n",
        "print(next_state_seq_actor)\n",
        "print(next_state_seq_critic)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMStateTuple(c=<tf.Tensor 'scan/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 128) dtype=float32>, h=<tf.Tensor 'scan/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, ?, 128) dtype=float32>)\n",
            "LSTMStateTuple(c=<tf.Tensor 'scan/TensorArrayStack_2/TensorArrayGatherV3:0' shape=(?, ?, 128) dtype=float32>, h=<tf.Tensor 'scan/TensorArrayStack_3/TensorArrayGatherV3:0' shape=(?, ?, 128) dtype=float32>)\n",
            "Tensor(\"scan/TensorArrayStack_4/TensorArrayGatherV3:0\", shape=(?, ?, 14), dtype=float32)\n",
            "Tensor(\"scan/TensorArrayStack_5/TensorArrayGatherV3:0\", shape=(?, ?, 1), dtype=float32)\n",
            "Tensor(\"transpose_1:0\", shape=(?, ?, 14), dtype=float32)\n",
            "Tensor(\"transpose_2:0\", shape=(?, ?, 1), dtype=float32)\n",
            "[<tf.Tensor 'transpose_3:0' shape=(?, ?, 128) dtype=float32>, <tf.Tensor 'transpose_4:0' shape=(?, ?, 128) dtype=float32>]\n",
            "[<tf.Tensor 'transpose_5:0' shape=(?, ?, 128) dtype=float32>, <tf.Tensor 'transpose_6:0' shape=(?, ?, 128) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf8tHYyRY4VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updatable agent\n",
        "\n",
        "# actor-critic losses\n",
        "# actor  -> logits, with shape: [batch, time, n_actions]\n",
        "# critic -> states, with shape: [batch, time, 1]\n",
        "r = 0\n",
        "\n",
        "logprobs_seq = tf.nn.log_softmax(logits_seq)\n",
        "logp_actions = tf.reduce_sum(logprobs_seq * tf.one_hot(sampled_actions_ph, n_actions),\n",
        "                             axis=-1)[:, r:-1]\n",
        "\n",
        "current_rewards = rewards_ph[:, r:-1] / 100.\n",
        "current_state_values = state_values_seq[:, r:-1, 0]\n",
        "\n",
        "next_state_values = state_values_seq[:, r+1:, 0] * mask_ph[:, r:-1]\n",
        "\n",
        "\n",
        "# policy gradient\n",
        "# compute 1-step advantage using current_rewards, current_state_values and next_state_values\n",
        "# have to manually adjust in the code for \"r\" the right size of cumulative_rewards_ph\n",
        "advantage = cumulative_rewards_ph - current_state_values\n",
        "assert advantage.shape.ndims == 2\n",
        "\n",
        "# compute policy entropy given logits_seq. Mind the sign!\n",
        "policy  = tf.nn.softmax(logits_seq, axis=-1)\n",
        "entropy = - tf.reduce_sum(policy * logprobs_seq, axis=-1)\n",
        "assert entropy.shape.ndims == 2\n",
        "\n",
        "actor_loss = - tf.reduce_mean(logp_actions * tf.stop_gradient(advantage))\n",
        "actor_loss -= 0.001 * tf.reduce_mean(entropy)\n",
        "\n",
        "# Prepare Temporal Difference error (States)\n",
        "target_state_values = (current_rewards + gamma * next_state_values + cumulative_rewards_ph) / 2 \n",
        "critic_loss = tf.reduce_mean(\n",
        "    (current_state_values - tf.stop_gradient(target_state_values))**2)\n",
        "\n",
        "train_step = tf.train.AdamOptimizer(1e-5).minimize(actor_loss + critic_loss)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm6ND-61Y4VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNl_YI7JY4VL",
        "colab_type": "text"
      },
      "source": [
        "# Train \n",
        "\n",
        "just run train step and see if agent learns any better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FengAe_yPtZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc_rewards(rewards, last_state_values, r=10, gamma=0.99):\n",
        "        # rewards at each step [batch, time]\n",
        "        # in a phase, last previous memory state [batch, state_dim]\n",
        "        # discount for reward\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session \n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "    \n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    curr_rewards = rewards / 100.\n",
        "    b_size, time = rewards.shape\n",
        "    \n",
        "    acc_reward = np.zeros((b_size, time-r-1), dtype='float32')\n",
        "    acc_reward[:,time-r-2] = last_state_values\n",
        "\n",
        "    for i in reversed(np.arange(time-r-2)):\n",
        "        acc_reward[:,i] = curr_rewards[:,i] + gamma * acc_reward[:,i+1]\n",
        "        \n",
        "    return acc_reward"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAkqEf_BY4VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_batch(rollout_length=rollout_length):\n",
        "    rollout_obs, rollout_actions, rollout_rewards, rollout_mask, prev_state_critic = pool.interact(rollout_length)\n",
        "\n",
        "    last_state_values = critic.get_state_values(prev_state_critic, rollout_obs[:,-1])\n",
        "    \n",
        "    rollout_cumulative_rewards = acc_rewards(rollout_rewards, last_state_values[:,0], r)\n",
        "    \n",
        "    feed_dict = {\n",
        "        init_state_actor_ph: actor.get_initial_state(n_parallel_games),\n",
        "        init_state_critic_ph: critic.get_initial_state(n_parallel_games),\n",
        "        observations_ph: rollout_obs,\n",
        "        sampled_actions_ph: rollout_actions,\n",
        "        mask_ph: rollout_mask,\n",
        "        rewards_ph: rollout_rewards,\n",
        "        cumulative_rewards_ph: rollout_cumulative_rewards\n",
        "    }\n",
        "\n",
        "    return feed_dict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoSvv_ewY4VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "from tqdm import trange\n",
        "from pandas import DataFrame\n",
        "\n",
        "moving_average = lambda x, **kw: DataFrame(\n",
        "    {'x': np.asarray(x)}).x.ewm(**kw).mean().values\n",
        "\n",
        "rewards_history = []"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_3kOalqY4VR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "380c64c6-832d-4c85-a1de-a9098263f1d4"
      },
      "source": [
        "iters = 2001\n",
        "for i in range(iters):\n",
        "    train_step.run(sample_batch())\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        rewards_history.append(np.mean(evaluate(actor, env, n_games=1)))\n",
        "        clear_output(True)\n",
        "        plt.plot(rewards_history, label='rewards')\n",
        "        plt.plot(moving_average(np.array(rewards_history),\n",
        "                                span=rollout_length), label='rewards ewma@'+str(rollout_length))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        if rewards_history[-1] >= 20000:\n",
        "            print(\"Your trainable_agent has just passed the minimum homework threshold\")\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdf7H8deXRVDEXdwQcRcQVMRdLNPccs1mqrFtWqym+dW0ubRMtm/WVDMtY1NNTTXVKJiamqamZlqBKbLKIiqooKgsys7n98e5KprlRYELl8/z8fDBveeee/kcwDdfvvecz9eICEoppZyLi6MLUEopVf003JVSyglpuCullBPScFdKKSek4a6UUk7IzdEFALRp00b8/f0dXYZSStUr0dHRR0Sk7fkeqxPh7u/vT1RUlKPLUEqpesUYs/fXHtNpGaWUckIa7kop5YQ03JVSygnViTn38yktLSUjI4OioiJHl6IczNPTE19fX9zd3R1dilL1Rp0N94yMDLy9vfH398cY4+hylIOICDk5OWRkZNC1a1dHl6NUvWHXtIwxpoUxZrExJtEYk2CMGWaMaWWMWWuMSbZ9bGnb1xhj3jDGpBhjYowxoRdTWFFREa1bt9Zgb+CMMbRu3Vr/glOqiuydc38dWC0ifYB+QAIwD1gnIj2Bdbb7ABOBnrZ/s4G3L7Y4DXYF+nOg1MW4YLgbY5oDo4D3AESkRESOA9OAD227fQhMt92eBnwklm1AC2NMh2qvXCml6jER4fOf9vFNfFaNvL49I/euwGHgA2PMz8aYfxljvIB2InLQts8hoJ3tdidgf6XnZ9i2ncUYM9sYE2WMiTp8+PDFH4GT+vbbb5k8ebKjy1BK1YB9OSeZ9a8fmLtkF0t3ZNbI57An3N2AUOBtERkAnODMFAwAYq34UaVVP0RkkYiEiUhY27bnvXq2ThERKioqauz1y8vLa+y1lVJ1Q3mF8N53exj/2iZiMnJ5dkZf3rhuQI18LnvCPQPIEJEfbPcXY4V91qnpFtvHbNvjmUDnSs/3tW2rd9LT0+nduzc33XQTffv25emnn2bQoEGEhITwxBNPAPDyyy/zxhtvAHD//fdzxRVXALB+/XpmzZoFwN13301YWBhBQUGnnwdW24W5c+cSGhrK//73P1avXk2fPn0IDQ0lIiLi9H4bN26kf//+9O/fnwEDBpCfn19bXwKlVDXZnZXPzLe/5+kV8Qzr3pq1D4xi1pAuuLjUzHtKFzwVUkQOGWP2G2N6i0gSMAaIt/27GXjB9vFL21OWAX82xnwGDAFyK03fXJQnl8cRfyDvUl7iFwI7NuOJKUEX3C85OZkPP/yQvLw8Fi9ezI8//oiIMHXqVDZt2kR4eDivvPIK9957L1FRURQXF1NaWsrmzZsZNWoUAM8++yytWrWivLycMWPGEBMTQ0hICACtW7dm+/btFBUV0bNnT9avX0+PHj249tprT9ewcOFC3nzzTUaMGEFBQQGenp7V+rVQStWckrIK3v42lX9sSMbb053Xr+vP1H4da/xEAXvPlvk/4BNjTAzQH3gOK9SvNMYkA2Nt9wFWAmlACvAu8KdqrbiWdenShaFDh7JmzRrWrFnDgAEDCA0NJTExkeTkZAYOHEh0dDR5eXl4eHgwbNgwoqKi2Lx5M+Hh4QB88cUXhIaGMmDAAOLi4oiPjz/9+qdCPDExka5du9KzZ0+MMdxwww2n9xkxYgQPPPAAb7zxBsePH8fNrc5enqCUqmTn/uNM/cd3/O2b3Uzs24G1949iWv9OtXIGmF0pISI7gLDzPDTmPPsKcM8l1nUWe0bYNcXLywuw5tznz5/PnXfe+Yt9unbtyr///W+GDx9OSEgIGzZsICUlhYCAAPbs2cPChQv56aefaNmyJbfccstZ52yfev3fMm/ePK666ipWrlzJiBEj+Prrr+nTp0/1HaRSqloVlpTzt29286/Nafh4e/Kvm8IYG9juwk+sRtpbxk7jx4/n/fffp6CgAIDMzEyys623GcLDw1m4cCGjRo0iPDycd955hwEDBmCMIS8vDy8vL5o3b05WVharVq067+v36dOH9PR0UlNTAfjvf/97+rHU1FSCg4OZO3cugwYNIjExsYaPVil1sbam5jDx9U0s2pTGtYP8WPPAqFoPdqjD7QfqmnHjxpGQkMCwYcMAaNq0KR9//DE+Pj6Eh4fz7LPPMmzYMLy8vPD09Dw9JdOvXz8GDBhAnz596Ny5MyNGjDjv63t6erJo0SKuuuoqmjRpQnh4+Ok3Tl977TU2bNiAi4sLQUFBTJw4sXYOWillt7yiUl5YlcinP+yjS+smfHrHEIZ3b+Oweow1i+JYYWFhcu5iHQkJCQQEBDioIlXX6M+DqsvWJWTxaGQs2flF3B7ejfvH9qJxI9ca/7zGmGgROd+UuY7clVLqYuUUFPPk8niW7TxA73bevHPjQPp3buHosgANd6WUqjIRYdnOAzy5PJ78olLuH9uLuy/vTiO3uvM2poa7UkpVwcHcQh6LjGVdYjb9OrfgpZkh9G7v7eiyfkHDXSml7FBRIXz2036eX5lAaUUFj10VwB9HdMW1hq4wvVQa7kopdQHpR04wLyKGbWlHGd69NS9cHYJf6yaOLus3abgrpdSvKCuv4P0te3hlzW4aubrwwtXBXDuoc71YY0DDXSmlziPxUB5zF8ewMyOXsQHteGZ6X9o3rz99nerOW7vqLPWpn3tWVhb33XcfISEhhIaGcvvtt7N//5mW/vv372f06NEEBgYSFBTE66+/fvqxBQsW0KlTp9NdL1euXOmIQ1DqtOKycl5du5vJb3xHxrFC/n79AN69aWC9CnbQcLdLTfdyh/rbzz01NZUJEyYwYsQIoqKi2L59O9dffz0zZsw43UrBzc2NV155hfj4eLZt28abb755VvO0+++/nx07drBjxw4mTZrkqENRip/3HWPK37/jjXXJTOnXkbUPXMaUWujgWBPqx7TMqnlwaFf1vmb7YJj4wq8+nJ6ezvjx4xkyZAjR0dGsXLmSL774gi+++ILi4mJmzJjBk08+ycsvv4yHhwf33nsv999/Pzt37mT9+vWsX7+e9957j08++YS7776bn376icLCQq655hqefPJJwOrnfu2117J27VrmzJlDixYt+Mtf/kKTJk0YOXLk6Vo2btzIfffdB1jriW7atAlv77NPvfr444954403KCkpYciQIbz11ltERESwdetWXn31VV5//XVef/110tLSSEtL48Ybb2TLli34+/tz/fXXs2rVKtzc3Fi0aBHz588nJSWFhx9+mLvuuouCggKmTZvGsWPHKC0t5ZlnnmHatGmA1av+ww8/PN3CGGDMmDF8/PHHPPjggyxdupQOHTrQoYO10qK3tzcBAQFkZmYSGBhYPd9LpS7RyZIyXlmzm/e37KF9M08+uGUQo/v4OLqsS6Ij99+QnJzMn/70J+Li4khKSiI5OZkff/yRHTt2EB0dfbqf++bNmwGIioqioKDgvP3co6KiiImJYePGjcTExJz+HKf6uU+fPp077riD5cuXEx0dzaFDh07vc6qf+44dO9i8eTONGzc+q86EhAQ+//xztmzZwo4dO3B1deWTTz45q7bNmzfTunVrMjMzz6oNwM/Pjx07dhAeHs4tt9zC4sWL2bZt2+mFRTw9PYmMjGT79u1s2LCBBx98EBFh9+7dtG3blpCQEFasWEFoaCjXXHMNM2fOpE+fPri4uHDkyJGzak1PT+fnn39myJAhp7f94x//ICQkhFtvvZVjx45Vx7dOKbt9n3KECa9t5r3v9jBriB9r7h9V74Md6svI/TdG2DXpVC934Kx+7gAFBQUkJydz0003ndXPPTQ09HQ/91MrNH3xxRcsWrSIsrIyDh48SHx8/OmR7vn6uQPccMMNLFq0CDjTz33WrFlcffXV+Pr6nlXnunXriI6OZtCgQQAUFhbi4+ND+/btKSgoID8/n/379/OHP/yBTZs2sXnzZq6++urTz586dSoAwcHBFBQU4O3tjbe3Nx4eHhw/fhwvLy8eeeQRNm3ahIuLC5mZmWRlZbFz506GDh1KeXk5Tz75JOvXryc3N5e+ffsC0LNnT/bs2UObNm1Of81mzpzJa6+9RrNmzQBr5P/4449jjOHxxx/nwQcf5P3336/Ob6NS55VbWMrzKxP47Kf9dG3jxeezhzKkW2tHl1Vt6ke4O0jlXut1uZ+7iHDzzTfz/PPP/+K5w4cP54MPPqB3796Eh4fz/vvvs3XrVl555ZXT+3h4eADg4uJy+vap+2VlZXzyySccPnyY6Oho3N3d8ff3P30Mrq6uHDlyhO7du9OiRQtatGhxerolOzsbHx9rBFRaWsrMmTNP/4I6pV27M61Q77jjjnrzJrKq39bEHeKxpbEcKSjmzsusRl+e7jXf6Ks22TUtY4xJN8bsMsbsMMZE2bZ9bru/w/b4Dtt2f2NMYaXH3qnJA6gtdbmf+5gxY1i8ePHpeo4ePcrevXt/UduAAQPYsGEDHh4eNG/e3O5jz83NxcfHB3d3dzZs2HD6tfv27csPP/xAmzZtSE1NJTc3l3379pGQkMCuXbvIzs6mS5cuiAi33XYbAQEBPPDAA2e99sGDZ1ZgjIyMPD3qV6omHCko5s+fbmf2f6Jp5dWIpfeMYP7EAKcLdqjayH20iJyeQBWR04t8GmNeAXIr7ZsqIv2rob46oy73cw8MDOSZZ55h3LhxVFRU4O7uzptvvkmXLl0IDw9n//79jBo1CldXVzp37lzlVZxmzZrFlClTCA4OJiws7PTzAwIC2LdvH0lJSTz22GOMHj2abt26MXXqVBYuXHh6emXLli385z//ITg4mP79rR+L5557jkmTJjFnzhx27NiBMQZ/f3/++c9/Vqk2pewhIizdkcmTy+M5WVzOg1f24q7Lu+Pu6rxvO9rVz90Ykw6EVQ73So8ZYB9whYgkG2P8gRUiYvcQTPu5118JCQnMmjWLF198kbFjxwKwfft2Dhw4wJQpU6r18+jPg7oYB44X8mjkLjYkHSbUrwUvzgyhZ7u61+jrYvxWP3d7f20JsMYYE22MmX3OY+FAlogkV9rW1RjzszFmozEm/FeKmm2MiTLGRB0+fNjOMlRdExAQwLJly1iyZAmhoaH069ePt99++6xTI5VyhIoK4T/b9nLlqxvZlnaUJ6YE8r+7hjtNsF+IvdMyI0Uk0xjjA6w1xiSKyCbbY9cD/62070HAT0RyjDEDgaXGmCARyav8giKyCFgE1sj9fJ9UROrlxQMNja+vL++8U3NvrdSF1cJU/ZJ2uIB5S3bxY/pRRvZow/NXB9O5Vd1u9FXd7Ap3Ecm0fcw2xkQCg4FNxhg34GpgYKV9i4Fi2+1oY0wq0AuI+sUL/wZPT09ycnJo3bq1BnwDJiLk5OTg6Vm/Lv1WjlFWXsG/vtvD39buxsPNhZeuCeF3A30bZIZcMNyNMV6Ai4jk226PA56yPTwWSBSRjEr7twWOiki5MaYb0BNIq2phvr6+ZGRkoFM2ytPT8xfn9it1rvgDecxZspPYzDzGB7Xj6Wl98WnWcAcF9ozc2wGRtt98bsCnIrLa9th1nD0lAzAKeMoYUwpUAHeJyNGqFubu7k7Xrl2r+jSlVANTXFbOP9an8Pa3qbRo4s5bs0KZ2Ld9gxytV3bBcBeRNKDfrzx2y3m2LQGWXHJlSil1AdF7jzJ3yS5SsguYGerL45MDaNGkkaPLqhP0ClWlVL1zoriMl79O4sOt6XRs3pgPbx3MZb3aOrqsOkXDXSlVr2xOPsz8iF1kHCvk5mFdeHhCH5p6aJSdS78iSql6IfdkKc98Fc//ojPo1taL/901jEH+rRxdVp2l4a6UqvNWxx7i8S9jOXqihD9d3p17x/R0yn4w1UnDXSlVZ2XnF7FgWRwrdx0isEMzPrhlEH072d/0riHTcFdK1TkiwpLtmTy9Ip7C0nIeHt+b2aO6OXWjr+qm4a6UqlMyjp3kkchYNu0+TFiXlrwwM4QePk0dXVa9o+GulKoTTjX6enG1tV7Bk1ODuHFoF1xcGvbFSBdLw10p5XCphwuYuziGqL3HGNWrLc/N6Itvy4bV6Ku6abgrpRymtLyCRZvSeH1dMo3dXVn4u37MDO3U4FsHVAcNd6WUQ8Rm5jJncQzxB/OYFNyeBVOD8PFuuI2+qpuGu1KqVhWVlvP6umQWbUqjlVcj3rkhlAl9Ozi6LKej4a6UqjU/pR9l7uIY0o6c4HcDfXnsqkCaN3F3dFlOScNdKVXjCorLeGl1Ih9t3Ytvy8b857bBhPfURl81ScNdKVWjNu4+zCMRuziQW8gtw/15eHxvvLTRV43Tr7BSqkYcO1HC01/FE7E9k+5tvVh81zAGdtFGX7XFrnA3xqQD+UA5UCYiYcaYBcAdwKl18B4RkZW2/ecDt9n2v1dEvq7mupVSdZSIsCr2EH/9MpbjJ0v5vyt6cM/oHtroq5ZVZeQ+WkSOnLPtbyKysPIGY0wg1vJ7QUBH4BtjTC8RKb+0UpVSdV12XhGPfxnL13FZBHdqzke3DiGwYzNHl9Ug1cS0zDTgMxEpBvYYY1KAwcDWGvhcSqk6QET4X3QGz6yIp7isgnkT+3D7yK64aaMvh7E33AVYY4wR4J8issi2/c/GmJuAKOBBETkGdAK2VXpuhm3bWYwxs4HZAH5+fhdZvlLK0fYfPcn8iF18l3KEwf6teGFmMN3aaqMvR7M33EeKSKYxxgdYa4xJBN4GnsYK/qeBV4Bb7f3Etl8QiwDCwsKkSlUrpRyuvEL4aGs6L61OwsXA09P7Mmuwnzb6qiPsCncRybR9zDbGRAKDRWTTqceNMe8CK2x3M4HOlZ7ua9umlHISyVn5zF0Sw/Z9x7m8d1uenRFMpxaNHV2WquSC4W6M8QJcRCTfdnsc8JQxpoOIHLTtNgOItd1eBnxqjHkV6w3VnsCP1V+6Uqq2lZZX8M63qfx9fQpeHq68dm1/pvXvqI2+6iB7Ru7tgEjbN88N+FREVhtj/mOM6Y81LZMO3AkgInHGmC+AeKAMuEfPlFGq/tuVkcvDi3eSeCifySEdWDA1iDZNPRxdlvoVRsTx091hYWESFRXl6DKUUudRVFrO377Zzbub0mjT1INnpvdlXFB7R5elAGNMtIiEne8xvUJVKfWrfkjLYV7ELvYcOcF1gzozf1IAzRtro6/6QMNdKfUL+UWlvLg6kY+37aNzq8Z8cvsQRvRo4+iyVBVouCulzrIhMZtHIneRlVfE7SO78sC4XjRppFFR3+h3TCkFwNETJTy1PI6lOw7Q06cpb909nAF+LR1dlrpIGu5KNXAiwoqYgyxYFkduYSn3jenJn0Z3x8NNG33VZxruSjVgWXlFPBoZyzcJWYT4NueTO4bQp702+nIGGu5KNUAiwuc/7efZlQmUlFXw6KQA/jjCXxt9ORENd6UamL05J5gfsYvvU3MY0rUVL84Mwb+Nl6PLUtVMw12pBqK8Qvhgyx4WrknC3cWF52YEc92gztroy0lpuCvVACQdymfOkhh27j/OmD4+PDOjLx2aa6MvZ6bhrpQTKymr4K1vU3hzQwrenu68fl1/pvbTRl8NgYa7Uk5q5/7jzFkcQ1JWPtP6d+SvkwNprY2+GgwNd6WcTGFJOa+uTeK97/bg4+3Jv24KY2xgO0eXpWqZhrtSTuT71CPMj9jF3pyT/GGIH/Mm9qGZpzb6aog03JVyAnlFpTy/MpH//riPLq2b8N87hjKse2tHl6UcyK5wN8akA/lAOVAmImHGmJeBKUAJkAr8UUSOG2P8gQQgyfb0bSJyVzXXrZSy+SY+i0eX7uJwfjGzR3Xj/rG9aNxIWwc0dFUZuY8WkSOV7q8F5otImTHmRWA+MNf2WKqI9K+uIpVSv5RTUMyTy+NZtvMAfdp7s+jGMPp1buHoslQdcdHTMiKyptLdbcA1l16OUupCRIRlOw+wYFkcBcVl3D+2F3df3p1Gbto6QJ1hb7gLsMYYI8A/RWTROY/fCnxe6X5XY8zPQB7wmIhsPvcFjTGzgdkAfn5+VS5cqYboYG4hj0XGsi4xm/6dW/DSNSH0auft6LJUHWRvuI8UkUxjjA+w1hiTKCKbAIwxj2IthP2Jbd+DgJ+I5BhjBgJLjTFBIpJX+QVtvyAWgbWGanUcjFLOqqJC+O9P+3h+ZSLlFcLjkwO5Zbg/rto6QP0Ku8JdRDJtH7ONMZHAYGCTMeYWYDIwRmwrbYtIMVBsux1tjEkFegG6ArZSF2HPkRPMWxLDD3uOMqJHa56fEYJf6yaOLkvVcRcMd2OMF+AiIvm22+OAp4wxE4A5wGUicrLS/m2BoyJSbozpBvQE0mqmfKWcV1l5Be9v2cMra3bTyM2FF2cG8/uwzto6QNnFnpF7OyDS9gPlBnwqIquNMSmAB9Y0DZw55XEUVviXAhXAXSJytEaqV8pJJRzMY+6SGGIycrkysB3PTO9Lu2aeji5L1SMXDHcRSQP6nWd7j1/Zfwmw5NJLU6rhKS4r580Nqby1IYXmjd35xx8GcFVwBx2tqyrTK1SVqiO27zvG3MUxJGcXMGNAJ/46OZCWXo0cXZaqpzTclXKwkyVlLPx6Nx98v4cOzTz54JZBjO7j4+iyVD2n4a6UA21JOcK8iBj2Hy3kxqFdmDOhN97a6EtVAw13pRwgt7CU575K4POo/XRt48Xns4cypJs2+lLVR8NdqVq2Ju4Qjy2NJedECXdd1p2/jO2Jp7s2+lLVS8NdqVpyOL+YBcvj+CrmIAEdmvHezYMI9m3u6LKUk9JwV6qGiQiRP2fy1Ip4ThaX89C4Xtx5WXfcXbXRl6o5Gu5K1aDM44U8GrmLb5MOE+pnNfrq4aONvlTN03BXqgZUVAif/LCXF1YlIsCCKYHcOEwbfanao+GuVDVLO1zAvCW7+DH9KOE92/DcjGA6t9JGX6p2abgrVU3Kyit4d/Me/vbNbjzdXHj5mhCuGeirrQOUQ2i4K1UN4g7kMndJDLGZeYwPasfT0/rio42+lANpuCt1CYpKy/n7+mTe2ZhGyyaNeHtWKBODOzi6LKU03JW6WNF7jzJncQyph08wM9SXxycH0KKJNvpSdYOGu1JVdKK4jJe/TuLDrel0bN6YD28dzGW92jq6LFWfiMChGIiNgJZdIOzWav8UGu5KVcGm3YeZH7GLA7mF3DS0Cw9P6ENTD/1vpOwgAllxEBcJcRFwNA1c3Gok2MHOcDfGpAP5QDlQJiJhxphWwOeAP5AO/F5Ejhnr1IDXgUnASeAWEdle/aUrVXtyT5by9FfxLI7OoFtbL764cxiD/Fs5uixVH2Qn2AI9Eo7sBuMCXUfBiL9AwBRoUjM/R1UZcowWkSOV7s8D1onIC8aYebb7c4GJWOum9gSGAG/bPipVL62OPcjjX8Zx9EQJf7q8O/eO0UZf6gKOJFtTLnGRcDjBCvQuI2DIXRAwFZrW/DTepfw9OQ243Hb7Q+BbrHCfBnwkIgJsM8a0MMZ0EJGDl1KoUrUtO7+IJ76MY1XsIYI6NuODWwbRt5M2+lK/Iif1zAg9KxYw0GU4TFpoBbp3u1otx95wF2CNMUaAf4rIIqBdpcA+hLWQNkAnYH+l52bYtp0V7saY2cBsAD8/v4urXqkaICIsjs7gma8SKCwtZ86E3twR3k0bfalfOpZ+JtAP7rS2dR4CE16EwKnQrKPDSrM33EeKSKYxxgdYa4xJrPygiIgt+O1m+wWxCCAsLKxKz1Wqpuw/epJHInexOfkIg/xb8sLMELq3beroslRdcnz/mUA/YHs7sVMYjHsWgqZDc1/H1mdjV7iLSKbtY7YxJhIYDGSdmm4xxnQAsm27ZwKdKz3d17ZNqTqrokL4aGs6L32dhAGemhbEDUO64KKNvhRAbibEf2md5ZLxk7Wt4wC48ikInG6dzljHXDDcjTFegIuI5NtujwOeApYBNwMv2D5+aXvKMuDPxpjPsN5IzdX5dlWXpWQXMG9JDFF7jzGqV1uem9EX35ba6KvByz9kC/RI2LfV2tY+GMY8YY3QW3VzbH0XYM/IvR0QaWt+5AZ8KiKrjTE/AV8YY24D9gK/t+2/Eus0yBSsUyH/WO1VK1UNSssrWLQpjde/SaZxI1de+V0/rg7tpI2+GrKCbFugL4W9WwABnyAY/RgEzYA2PRxdod0uGO4ikgb0O8/2HGDMebYLcE+1VKdUDYnNzGXO4hjiD+ZxVXAHFkwNoq23h6PLUo5wIgcSlllTLunfgVRAm95w+Twr0Nv2dnSFF0UvrVMNSlFpOa+vS2bRpjRaeTXinRsGMqFve0eXpWrbyaOQuMKacknbCFIOrXtA+ENWoPsEQD3/C07DXTUYP6UfZe7iGNKOnOD3Yb48OimQ5k3cHV2Wqi2FxyHxK1ugb4CKMmjpDyPug75XQ7u+9T7QK9NwV06voLiMl1Yn8tHWvfi2bMzHtw1hZM82ji5L1YaiPEhaZU25pKyDilJo4QfD7rFG6B36O1WgV6bhrpzahqRsHo3YxcG8Iv44wp+HxvXGSxt9ObfiAti92hqhJ6+F8mJo1gmG3AlBV0OnUKcN9Mr0p1w5pWMnSnh6RTwRP2fSw6cpi+8azsAuLR1dlqopJScgeY3VzyV5DZQVgXcHq+Ni36uti4xcGtYVxhruyqmICCt3HeKJZbEcP1nKvVf04J4reuDhpo2+nE5poTUyj4uA3V9D6Unw8oHQm6wpl85DG1ygV6bhrpxGdl4Rjy2NZU18FsGdmvPRrUMI7NjM0WWp6lRaBKnrrCmXpFVQUgBN2kC/66wply7DwUV/kYOGu3ICIsL/ojJ4+qt4SsoqmD+xD7eN7IqbNvpyDmUl1tktsRGQtBKK86BxS+g70xqh+4eDq0bZufQrouq1fTlWo6/vUo4wuGsrXrg6mG7a6Kv+Ky+1zj+Pi4TE5VCUC57NrU6LQTOg62Xgqqex/hYNd1UvlVcI//4+nYVfJ+HqYnhmel/+MNhPG33VZ+VlkL7JCvSE5VB4DDyaQZ+rrCmXbpeDmy5Abi8Nd1XvJGflM2dJDD/vO87o3m15dkYwHVs0dnRZ6mJUlFs9XGIjrBYAJ3OgUVPoPckaofcYA27aFik1ayUAABqESURBVOJiaLireqOkrIJ3Nqbyj/UpeHm48tq1/ZnWv6M2+qpvKiqsLotxkVaTrhPZ4N4Eek2wTlvsMRbc9Zf1pdJwV/VCTMZx5iyOIfFQPlP6deSJKYG0aaojunqjosLqgx4XYXVcLDgEbo2h1zhrhN5zPDTSNsvVScNd1WlFpeX8be1u3t2cRltvD969KYwrA2t3LUp1kUQgM9qacolfCnmZ4OoBPa+0Ar3XBPDQN79rioa7qrO2peUwb0kM6TknuX5wZ+ZNDKB5Yz1Dok4TgQM/25ahWwq5+8C1EXQfA2MXWIHuqdce1AYNd1Xn5BeV8sKqRD75YR9+rZrw6e1DGN5DG33VWSJwaJdtyiXSWjTaxQ26XwGj51tvjjZu4egqGxy7w90Y4wpEAZkiMtkYsxnwtj3sA/woItONMZdjLbm3x/ZYhIg8VY01Kye2PjGLRyNjycor4vaRXXlgXC+aNNIxSJ0jAtnxVpjHRsDRVDCu1umK4Q9Zpy82aeXoKhu0qvyvuQ9IAJoBiEj4qQeMMUs4s4YqwGYRmVwtFaoG4eiJEp5aHsfSHQfo1a4pb80azgA/bfRV52Qn2qZcIuFIEhgX6wrREfdCnyng1drRFSobu8LdGOMLXAU8CzxwzmPNgCvQtVLVRRARlsccZMGyOPKLSrlvTE/uGd2DRm7aOqDOOJJyZsolOx4w4D8ShsyGgGnQtK2jK1TnYe/I/TVgDmemYSqbDqwTkbxK24YZY3YCB4CHRCTu3CcZY2YDswH8/PyqVLRyDodyrUZf3yRk0c+3OS9eM4Q+7fXNtjrhaJptyiUSsnZZ2/yGwcSXrRYA3ro0YV13wXA3xkwGskUk2jaffq7rgX9Vur8d6CIiBcaYScBSoOe5TxKRRcAigLCwMLmI2lU9JSJ89tN+nvsqgdKKCh6dFMCtI7viqq0DHOvY3jNTLgd3WNt8B8P45yFoOjTr6Nj6VJXYM3IfAUy1BbUn0MwY87GI3GCMaQMMBmac2rnyCF5EVhpj3jLGtBGRI9VdvKp/9uacYN6SXWxNy2Fot1a8cHUI/m28HF1Ww5WbcSbQM6OtbZ0GwrhnIHA6tOjs2PrURbtguIvIfGA+gG3k/pCI3GB7+BpghYgUndrfGNMeyBIRMcYMBlyAnOouXNUv5RXCB1v2sHBNEu4uLjx/dTDXhnXWRl+OkHfAuuw/NgIyfrS2degHY5+0Rugt/R1anqoel3qO2XXAC+dsuwa42xhTBhQC14mITrs0YEmHrEZfO/cfZ2yAD89MD6Z9c09Hl9Ww5GdZgR4XafV1QaBdMFzxuHW1aOvujq5QVTNTF3I3LCxMoqKiHF2GqmYlZRW89W0Kb25IwdvTnQVTg5gS0kEbfdWWgsNWp8W4SEj/DhDwCbTCPGgGtPnFW2GqnjHGRItI2Pke06tDVI3Ysf84cxfHkJSVz7T+HXliShCtvLQXd407kWMtbhEXCXs2gVRAm15w2VxrysUnwNEVqlqi4a6qVWFJOa+sSeL9LXvw8fbkvZvDGBOgjb5qVOExSFhhBXratyDl0KobjHzAaqHrEwj611KDo+Guqs33qUeYt2QX+46e5A9D/Jg3sQ/NPLXRV40oyoXEldbFRakboKIUWnSxrhQNmgHtQzTQGzgNd3XJ8opKeX5lAv/9cT/+rZvw3zuGMqy7XoZe7YrzIWmVNUJP+QbKS6B5Zxh6l7UMXccBGujqNA13dUm+ic/i0aW7OJxfzJ2juvGXsb1o3MjV0WU5j+IC2L3aCvTktVBeDN4dYdAd1pRLp4Ea6Oq8NNzVRckpKGbB8niW7zxAn/bevHtTGCG+2ta1WpSchOQ11pTL7jVQVghN20PYH60pF9/B4KK9d9Rv03BXVSIifLnjAE8uj6OguIwHruzFXZd110Zfl6q0CFLWWiP0pNVQegK82sKAWdaUi99QcNG/iJT9NNyV3Q4cL+SxpbGsT8ymf+cWvHRNCL3ana+XnLJLWTGkrreuFE1aBSX50KQ1hPzeGqH7j9RAVxdNw11dUEWF8OmP+3hhVSLlFcLjkwO5Zbi/Nvq6GGUl1umKcZGQ+BUU50LjltDXdmGR/yhw1f+W6tLpT5H6TXuOnGDekhh+2HOUET1a8/yMEPxa6yr1VVJeCns2WoGesAKKjoNHcwiYbE25dLsMXPWUUVW9NNzVeZWVV/Ded3t4de1uGrm58NLMEH4X5qutA+xVXgZ7v7OmXBKWQ+FRaORtLT8XNAO6jwY3D0dXqZyYhrv6hfgDecxdEsOuzFyuDGzHM9P70q6ZNvq6oIpy2Pu9bYS+DE4cBncv6D3ROm2x+xhw16+jqh0a7uq04rJy/rE+hbe/TaVFE3fe/EMok4Lb62j9t1RUwP5tVqDHfwkFWeDeBHqNt6Zcel4J7o0dXaVqgDTcFQDRe48xd0kMKdkFXD2gE49PDqSlNvo6v4oKyIyyplzil0L+QXDzhJ7jrCmXXuOhkS5AohxLw72BO1lSxstfJ/Hv79Pp0MyTD/44iNG9fRxdVt0jApnbbQtFL4W8DHBtBD2utKZceo0HDz0tVNUddoe7McYViAIyRWSyMebfwGVArm2XW0Rkh7H+hn8dmASctG3fXr1lq+rwXfIR5kXEkHGskJuGdWHOhD409dDf96eJWGuJnlqG7vg+cHGHHmNgzOPWXLpnc0dXqdR5VeV/8n1AAlB5efqHRWTxOftNxFoQuycwBHjb9lHVEbmFpTz7VTxfRGXQtY0XX9w5jMFdWzm6rLpBBLJirSmXuEg4tgdc3KDbaLhsHvSZZJ2XrlQdZ1e4G2N8gauAZ4EHLrD7NOAj29J624wxLYwxHUTk4KWVqqrD13GHeHxpLDknSrj78u7cN6Ynnu56FSRZ8bYRegTkpIBxha6jIPwB6DMZmugvP1W/2Dtyfw2YA5w7qfisMeavwDpgnogUA52A/ZX2ybBtOyvcjTGzgdkAfn5+Va9cVcnh/GIWLIvjq10HCejQjPduHkSwbwOfUjicdGbK5XAiGBfrkv9h90DAVPBq4+gKlbpoFwx3Y8xkIFtEoo0xl1d6aD5wCGgELALmAk/Z+4lFZJHteYSFhTl+IVcnJSJEbM/kqRXxFJaU8/D43swe1Q131wba6Csn9cyUS3YcYKDLcJi00Ap0b101SjkHe0buI4CpxphJgCfQzBjzsYjcYHu82BjzAfCQ7X4m0LnS831t21QtyzxeyCMRu9i4+zADu7TkxZnB9PBpgGd0HN1zZsrl0C5rW+ehMPElK9CbdXBsfUrVgAuGu4jMxxqlYxu5PyQiN5yaR7edHTMdiLU9ZRnwZ2PMZ1hvpObqfHvtqqgQPv5hLy+uSkSABVMCuWmYPy4NqdHX8X1nplwO/Gxt8x0E45+DwOnQvJNj61Oqhl3KeW+fGGPaAgbYAdxl274S6zTIFKxTIf94SRWqKkk9XMC8JTH8lH6M8J5teG5GMJ1bNZBGX7kZ1jnocZHWRUZgLT135dMQNB1a6Hs7quGoUriLyLfAt7bbV/zKPgLcc6mFqaopLa/g3c1pvPZNMp5uLrx8TQjXDGwAjb7yDlqX/cdFwP4frG3tQ2DME9bVoq26OrY+pRxEr1hxArGZucxdEkPcgTwmBLXnqelB+Hg7cYOqgmxboEdajboQaNcXrngMAmdAmx6OrlAph9Nwr8eKSsv5+/pk3tmYRssmjXh7VigTg530zcETR6xOi7ERsHcLSAW07QOXz7emXNr2dnSFStUpGu71VFT6UeYsiSHt8AmuGejLY1cF0KKJkzX6OnnU6oUeFwl7NoGUQ+seEP6Q1c/FJ8DRFSpVZ2m41zMniq1GXx9uTadj88Z8dOtgRvVq6+iyqk/hMWv5ubhIazm6ijJo2RVG/sWaQ2/XF5z9fQSlqoGGez2ycfdhHonYxYHcQm4e5s/D43vj5QyNvopyrQWiYyOsBaMrSq0zW4b92Qr0Dv000JWqIidIBud3/GQJT69IYMn2DLq19eJ/dw4jzL+e9zopzoek1dYIPWUtlJdAM18Ycqc15dIxVANdqUug4V7Hrdp1kMe/jOPYyRLuGd2d/7uiHjf6KjkBu22BnrwWyorAuyMMut1atajTQHBpoG0RlKpmGu51VHZeEX/9Mo7VcYcI6tiMD28dRFDHetjoq+SkNTKPjYDdX0NZITRtB6E3W1MunYdooCtVAzTc6xgRYXF0Bk+viKeorIK5E/pwR3hX3OpTo6/SIkj5xhqhJ62C0hPQpA30/4M15eI3DFzq6V8fStUTGu51yP6jJ3kkchebk48wyL8lL8wMoXvbpo4uyz5lxZC6wbpSNHEllORD41YQ8jtrhN5lJLjqj5tStUX/t9UB5RXCR1vTefnrJAzw9LQgZg3pUvcbfZWVwJ6N1gg9YQUU54JnC+uioqAZ1mIXru6OrlKpBknD3cFSsvOZu2QX0XuPcVmvtjw7oy++Letwo6/yskqBvhyKjoNHc+hzlTXl0vUycHOyi6mUqoc03B2ktLyCf25M5Y11KTTxcOXV3/djxoBOdbPRV0U5pH9nTbkkLIeTOdDI21pPNGgGdL8C3DwcXaVSqhINdweIzczl4cUxJBzM46qQDiyYEkRb7zoWjhXlsG+rNUKP/xJOHAZ3L+g9wTptscdYcHfi5mRK1XMa7rWoqLSc175J5t3NabTyasQ/bxzI+KD2ji7rjIoKyPjROm0x/ksoOARujaHXeGvKpceV0KgOTxkppU7TcK8lP+45yrwlMaQdOcG1YZ15ZFIAzZvUgTcbRSAjyppyiVsK+QfAzRN6XmlNufSaAI28HF2lUqqK7A53Y4wrEAVkishkY8wnQBhQCvwI3Ckipbal+L4E9tieGiEidi+c7Wzyi0p5aXUS/9m2F9+Wjfn4tiGM7NnGsUWJwIHttmXolkLufnBtZE21BD1lTb14NMC1VpVyIlUZud8HJADNbPc/AU4tkv0pcDvwtu3+ZhGZXC0V1mMbkrJ5NGIXB/OKuHVEVx4a34smjRz0x5IIHIqxplziIuH4XnBxt94MHf2o9eaoZz28AlYpdV52JY0xxhe4CngWeABARFZWevxHwLcmCqyPjp0o4ekV8UT8nEkPn6Ysvms4A7u0rP1CRCArzjZCj4CjaeDiBt0uh8vmWKcvNnZAXUqpGmfvMPI1YA7wi7/VjTHuwI1YI/tThhljdgIHgIdEJO48z5sNzAbw83OOhYtFhK92HeSJL+PILSzl3it6cM8VPfBwq+VL7bMTbIEeCUd2g3GxLiga8RcImAJN6nlHSaXUBV0w3I0xk4FsEYm2zaef6y1gk4hstt3fDnQRkQJjzCRgKdDz3CeJyCJgEUBYWJhcZP11RlZeEY8vjWVNfBbBnZrz8e1DCOjQ7MJPrC5Hks9MuRxOAAz4j4Qhd0HAVGjqRAt6KKUuyJ6R+whgqi2oPYFmxpiPReQGY8wTQFvgzlM7i0hepdsrjTFvGWPaiMiR6i6+LhARvojazzNfJVBSVsH8iX24bWQtNfrKST0zQs+KBYzVlGvSQivQvdvVfA1KqTrpguEuIvOB+QC2kftDtmC/HRgPjBGRilP7G2PaA1kiIsaYwYALkFMTxTvavpyTzIuI4fvUHAZ3bcWLM0Po2qaGTxs8ln4m0A/utLZ1HgITXoDAadCsY81+fqVUvXApp268A+wFttoumT91yuM1wN3GmDKgELhOROr9tEtl5RXCv79PZ+HXSbi6GJ6Z3pc/DParuUZfx/efCfQD261tncJg3LNWk67m+l62Uupspi7kblhYmERFRTm6DLvszspnzuIYduw/zujebXl2RjAdWzSu/k+Um2ldJRoXARk/Wds69LeuFA2cDi27VP/nVErVK8aYaBEJO99jeoWqnUrKKnhnYyp/X59MUw83Xr+uP1P7dazeRl/5h2yBHmn1dQFoHwxj/mpdLdqqW/V9LqWUU9Nwt8PO/ceZuySGxEP5TOnXkQVTAmndtJoafRVk2wJ9KezdAgj4BMHox6xAb9Ojej6PUqpB0XD/DYUl5fztm938a3Mabb09ePemMK4MrIYzUE7kQMIya8ol/TuQCmjTGy6fZ025+PS59M+hlGrQNNx/xdbUHOZHxJCec5LrB3dm/qQAmnleQqOvk0chcYU15ZK2EaQcWnWH8AetFro+AVAXe7krpeolDfdz5BWV8sKqRD79YR9+rZrw6e1DGN7jIht9FR6HxK9sgb4BKsqgpT+MuM+acmkfrIGulKoRGu6VrE/M4pGIWLLzi7gjvCsPXNmbxo2q2DqgKA+SVllTLinroKIUmvvB0D9ZZ7p06K+BrpSqcRruQE5BMU+tiOfLHQfo3c6bd24cSP/OLex/geIC2L3aGqEnr4XyYmjWCYbcaU25dArVQFdK1aoGHe4iwrKdB3hyeTz5RaX8ZWxP/nR5Dxq52dE6oOQEJK+x+rkkr4GyIvDuAGG3WlMuvoPApRZaECil1Hk02HA/mFvIY5GxrEvMpl/nFrw0M4Te7S+wQEVpoTUyj4uA3V9D6Unw8oEBN1pTLp2HaqArpeqEBhfuFRXCZz/t5/mVCZRWVPDYVQH8cURXXH+tdUBpEaSus6ZcklZBSQE0aQP9rrNG6F1GgEstt/RVSqkLaFDhnn7kBPMiYtiWdpRh3VrzwsxgurQ+T6OvshLr7JbYCEhaCcV51qIWfWdage4fDq4N6kunlKpnGkRClVcI73+3h1fWJuHu4sLzVwdz3aDOZ7cOKC+1zj+Pi4TE5VCUay07FzAV+s6ArpeBax1Y0Foppezg9OGeeCiPuYtj2JmRy9gAH56ZHkz75p7Wg+VlkL7JCvSE5VB4DDyaWcvPBc2AbqPBrZFjD0AppS6C04Z7cVk5b25I5a0NKTRv7M7frx/A5JAOGKmAPZusKZeEZXAyBxo1hd4TrdMWu18B7p6OLl8ppS6JU4b7z/uOMXdJDLuzCpjevyN/nRxAqyPRsPJVq0nXiWxwbwK9JlhnufQYC+410LZXKaUcxKnC/WRJGa+s2c37W/bQwbsRiye7EJb/GbyzFAoOgVtj6DXOmnLpOR4aNXF0yUopVSPsDndjjCsQBWSKyGRjTFfgM6A1EA3cKCIlxhgP4CNgINbyeteKSHq1V36O71OOMG9JDK2O7+I/neIYXrwZl28OgKsH9LzSCvReE8CjaU2XopRSDleVkft9QALQzHb/ReBvIvKZMeYd4DbgbdvHYyLSwxhznW2/a6ux5rPknizhoyVLcU/6ki/cf6C9x2E46m5NtYxdYM2leza70MsopZRTsSvcjTG+wFXAs8ADxjqH8ArgD7ZdPgQWYIX7NNttgMXAP4wxpibWUU3+eRONv7yd/yOLcndX6HYFBF8NvSdB4yr0hlFKKSdj78j9NWAOcOr6/NbAcREps93PADrZbncC9gOISJkxJte2/5HKL2iMmQ3MBvDz87uo4n38epHu2RkZ9CCdh/0OmrS6qNdRSilnc8FwN8ZMBrJFJNoYc3l1fWIRWQQsAmuB7It5jeat29Nv3rrqKkkppZyGPSP3EcBUY8wkwBNrzv11oIUxxs02evcFMm37ZwKdgQxjjBvQHOuNVaWUUrXkgi0MRWS+iPiKiD9wHbBeRGYBG4BrbLvdDHxpu73Mdh/b4+trYr5dKaXUr7uU/rRzsd5cTcGaU3/Ptv09oLVt+wPAvEsrUSmlVFVV6SImEfkW+NZ2Ow0YfJ59ioDfVUNtSimlLpKuLKGUUk5Iw10ppZyQhrtSSjkhDXellHJCpi6cpWiMOQzsvYSXaMM5V8A6uYZ2vKDH3FDoMVdNFxFpe74H6kS4XypjTJSIhDm6jtrS0I4X9JgbCj3m6qPTMkop5YQ03JVSygk5S7gvcnQBtayhHS/oMTcUeszVxCnm3JVSSp3NWUbuSimlKtFwV0opJ1Rvwt0YM8EYk2SMSTHG/KLTpDHGwxjzue3xH4wx/rVfZfWy45gfMMbEG2NijDHrjDFdHFFndbrQMVfab6YxRowx9f60OXuO2Rjze9v3Os4Y82lt11jd7PjZ9jPGbDDG/Gz7+Z7kiDqrizHmfWNMtjEm9lceN8aYN2xfjxhjTOglf1IRqfP/AFcgFegGNAJ2AoHn7PMn4B3b7euAzx1ddy0c82igie323Q3hmG37eQObgG1AmKPrroXvc0/gZ6Cl7b6Po+uuhWNeBNxtux0IpDu67ks85lFAKBD7K49PAlYBBhgK/HCpn7O+jNwHAykikiYiJcBnWAtxVzYNa6FusBbmHmNbyLu+uuAxi8gGETlpu7sNa0Ws+sye7zPA08CLQFFtFldD7DnmO4A3ReQYgIhk13KN1c2eYxasVd/AWs3tQC3WV+1EZBNw9Dd2mQZ8JJZtWCvddbiUz1lfwv30ots2lRfk/sU+Yi39d2ph7vrKnmOu7Das3/z12QWP2fbnamcR+ao2C6tB9nyfewG9jDFbjDHbjDETaq26mmHPMS8AbjDGZAArgf+rndIcpqr/3y+oSot1qLrJGHMDEAZc5uhaapIxxgV4FbjFwaXUNjesqZnLsf4622SMCRaR4w6tqmZdD/xbRF4xxgwD/mOM6SsiFY4urL6oLyP3U4tun1J5Qe5f7OMkC3Pbc8wYY8YCjwJTRaS4lmqrKRc6Zm+gL/CtMSYda25yWT1/U9We73MGsExESkVkD7AbK+zrK3uO+TbgCwAR2Qp4YjXYclZ2/X+vivoS7j8BPY0xXY0xjbDeMF12zj7OtjD3BY/ZGDMA+CdWsNf3eVi4wDGLSK6ItBERf7EWbN+GdexRjim3Wtjzs70Ua9SOMaYN1jRNWm0WWc3sOeZ9wBgAY0wAVrgfrtUqa9cy4CbbWTNDgVwROXhJr+jod5Gr8G7zJKwRSyrwqG3bU1j/ucH65v8PSAF+BLo5uuZaOOZvgCxgh+3fMkfXXNPHfM6+31LPz5ax8/tssKaj4oFdwHWOrrkWjjkQ2IJ1Js0OYJyja77E4/0vcBAoxfpL7DbgLuCuSt/jN21fj13V8XOt7QeUUsoJ1ZdpGaWUUlWg4a6UUk5Iw10ppZyQhrtSSjkhDXellHJCGu5KKeWENNyVUsoJ/T+c83ip+QPkHgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il8-jD91Y4VV",
        "colab_type": "text"
      },
      "source": [
        "### \"Final\" evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rPp_T9yB91q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(make_env(), directory=\"videos\", force=True) as env_monitor:\n",
        "    final_rewards = evaluate(agent, env_monitor, n_games=n_parallel_games)\n",
        "\n",
        "print(\"Final mean reward\", np.mean(final_rewards))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBeg64nWY4VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t_y0TcOY4Va",
        "colab_type": "text"
      },
      "source": [
        "### POMDP setting\n",
        "\n",
        "The Atari game we're working with is actually a POMDP: your agent needs to know timing at which enemies spawn and move, but cannot do so unless it has some memory. \n",
        "\n",
        "Let's design another agent that has a recurrent neural net memory to solve this.\n",
        "\n",
        "__Note:__ it's also a good idea to scale rollout_len up to learn longer sequences. You may wish set it to >=20 or to start at 10 and then scale up as time passes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJgo_LgQY4Vg",
        "colab_type": "text"
      },
      "source": [
        "### Now let's train it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyzuw5WcY4Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A whole lot of your code here: train the new agent with GRU memory.\n",
        "# - create pool\n",
        "# - write loss functions and training op\n",
        "# - train\n",
        "# You can reuse most of the code with zero to few changes"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}